{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id1'></a>\n",
    "# BOM Weather\n",
    "\n",
    "### A project evaluating the Persistence Model against the AUS Bureau of Meteorology.\n",
    "We often get a 7 day weather forecast but don't often go back to see how accurate the predictions were for 7 days ago.   \n",
    "This project looks to explore how accurate the weather forecast is according to a what is known as the Persistence Model.\n",
    "The Persistence Model hypothesis for the weather domain is that \"The weather tomorrow will be the same as today\",   \n",
    "or in mathematical terms Weather(t+1) = Weather(t), (t being today, or chosen point in time).\n",
    "\n",
    "The BOM forecasts are known to be very accurate for t = 1,2 and 3 days into the future, so this project will evaluate the whole 7 day forecast.\n",
    "\n",
    "The persistence model, also called the na√Øve predictor, is often used as a reference as it is a good ground estimation of other algorithms,and often used as a reference for determining the skill factor of a competing forecast model.   \n",
    "\n",
    "The second part of this project will try to predict the weather, using the persistence model as a feature, giving some adjustment to standard forcasting models Facebook prophet and Random Forrest trained on historical data.\n",
    "\n",
    "All data is available for free via the BOM website and examples are stored in the repository.\n",
    "\n",
    "[Click here for EDA notebook locally](eda.ipynb#section_id1)   \n",
    "[Click here for EDA notebook GitHub](https://github.com/bfgdigital/BOM_Weather/blob/main/notebooks/eda.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a date for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterdays's date was: 2020-10-30\n",
      "Today's date is: 2020-10-31\n",
      "Tomorrows's date is: 2020-11-01\n",
      "Day after that is: 2020-11-02\n"
     ]
    }
   ],
   "source": [
    "today = dt.date.today()\n",
    "todaystr = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "yesterday = dt.date.today() - pd.DateOffset(days=1)\n",
    "yesterdaystr = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "tomorrow = dt.date.today() + pd.DateOffset(days=1)\n",
    "tomorrowstr = tomorrow.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "day_after_tomorrow = dt.date.today() + pd.DateOffset(days=2)\n",
    "day_after_tomorrowstr = day_after_tomorrow.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f'Yesterdays\\'s date was: {yesterday.date()}')\n",
    "print(f'Today\\'s date is: {today}')\n",
    "print(f'Tomorrows\\'s date is: {tomorrow.date()}')\n",
    "print(f'Day after that is: {day_after_tomorrow.date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA Sources \n",
    "- Data Comes From: ftp://ftp.bom.gov.au/anon/gen/fwo/\n",
    "- Melbourne Forecast File: ftp://ftp.bom.gov.au/anon/gen/fwo/IDV10450.xml\n",
    "\n",
    "The url for the BOM API is:\n",
    "https://api.weather.bom.gov.au/v1/locations/r1r143/forecasts/daily   \n",
    "Be Aware that the update is adjusted every 10mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = {\n",
    "'LakeEildon' : 'https://api.weather.bom.gov.au/v1/locations/r1ru3qn/forecasts/daily',\n",
    "'FallsCreek' : 'https://api.weather.bom.gov.au/v1/locations/r32wr3e/forecasts/daily',\n",
    "'Mildura' : 'https://api.weather.bom.gov.au/v1/locations/r1vjdbz/forecasts/daily',\n",
    "'Corryong' : 'https://api.weather.bom.gov.au/v1/locations/r394jdk/forecasts/daily',\n",
    "'WilsonsProm' : 'https://api.weather.bom.gov.au/v1/locations/r3046k1/forecasts/daily',\n",
    "'Melbourne' : 'https://api.weather.bom.gov.au/v1/locations/r1r143/forecasts/daily',\n",
    "} # Melbourne last so it will be used for this iteration of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save full forecast for future reference and development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,url in locations.items():\n",
    "    response = requests.get(url)\n",
    "    weather_dict = response.json() # format as json\n",
    "    latest_forecast = weather_dict\n",
    "    api_forecast = pd.DataFrame(latest_forecast['data'])\n",
    "    api_forecast.index=api_forecast['date']\n",
    "    filename = '../data/forecast_records/forecast_' + str(name) + '_' + todaystr + '.csv'\n",
    "    api_forecast.to_csv(filename) # backup file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a call backup to prevent constant pinging of API during development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_backup():\n",
    "    latest_forecast = weather_dict.copy()\n",
    "    return latest_forecast\n",
    "\n",
    "call_backup();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Forecast date is correct**   \n",
    "Establish current dates using datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API values change depending on the time of day.   \n",
    "We need to handle the dates with a forecast status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Forecast was issued on: 2020-10-29\n"
     ]
    }
   ],
   "source": [
    "issue_time = pd.to_datetime(latest_forecast['metadata']['issue_time']).date()\n",
    "print('\\n',f'Forecast was issued on: {issue_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API forecast row 0 is for tomorrow\n"
     ]
    }
   ],
   "source": [
    "forecast_status = 0\n",
    "if issue_time == today:\n",
    "    print('API forecast row 0 is for tomorrow')\n",
    "    forecast_status = 1\n",
    "elif issue_time == yesterday:\n",
    "    print('API forecast row 0 is for today')\n",
    "else:\n",
    "    print('Check API data.')\n",
    "    forecast_status = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast date index moved forwards 1 day.\n",
      "\n",
      " Todays Max: 2020-10-29 00:00:00 [22], Forecasts: [20, 18, 19, 26, 28, 21, 16]\n"
     ]
    }
   ],
   "source": [
    "lf = pd.DataFrame(latest_forecast['data'])\n",
    "lf['date'] = pd.to_datetime(lf['date']).dt.date\n",
    "\n",
    "if forecast_status == 1: # We want to bump the date column forwards 1 day.\n",
    "    lf[['date']] = lf[['date']] + pd.DateOffset(days=1) # add 1 day\n",
    "    print(f\"Forecast date index moved forwards 1 day.\")\n",
    "else:\n",
    "    forecast_status == 0 # We want to bump the date column forwards 1 day.\n",
    "    print(f\"Dates are correct, no need to change index\")\n",
    "\n",
    "lf.index = lf['date']\n",
    "print('\\n',f\"Todays Max: {lf.index[0]} {list(lf['temp_max'][:1])}, Forecasts: {list(lf['temp_max'][1:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Temps File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.read_csv('../data/temps.csv',infer_datetime_format=True,index_col=0)\n",
    "\n",
    "# Reset location.\n",
    "def reset_location():\n",
    "    temps = pd.read_csv('../data/temps.csv',infer_datetime_format=True,index_col=0)\n",
    "    return temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with existing forecast file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBC\n",
    "# call_backup();\n",
    "number_of_forecasts = len(latest_forecast['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of new data\n",
    "Latest observations taken from BOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New forecasts:\t8\n",
      "Starting on:\t2020-10-29 00:00:00\n",
      "Ending on:\t2020-11-05 00:00:00\n",
      "Today's Temp:\t\t22\n",
      "Tomorrow's Temp:\t20 \n",
      "\n",
      "\u001b[1mHere's today's forecast: \n",
      "Cloudy. Medium (50%) chance of showers, becoming less likely late this evening. The chance of thunderstorms early this evening, mainly about northern and eastern suburbs. Winds south to southwesterly 15 to 25 km/h becoming light in the evening.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(f\"New forecasts:\t{number_of_forecasts}\")\n",
    "print(f\"Starting on:\t{lf['date'][0]}\")\n",
    "print(f\"Ending on:\t{lf['date'][-1]}\")\n",
    "print(f\"Today's Temp:\t\t{lf['temp_max'][0]}\")\n",
    "print(f\"Tomorrow's Temp:\t{lf['temp_max'][1]}\",\"\\n\")\n",
    "print(color.BOLD + f\"Here's today's forecast: \\n{lf['extended_text'][0]}\" + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append new data to existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Row: ['Melbourne', 22, 20, 18, 19, 26, 28, 21, 16], with 8/7 days\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 9, index implies 8.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a069c4f59746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemperatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'New Row: {string}, with {len(string)-1}/7 days'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnew_forecast_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroll_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    314\u001b[0m                             \u001b[0;34mf\"Length of passed values is {len(data)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                             \u001b[0;34mf\"index implies {len(index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 9, index implies 8."
     ]
    }
   ],
   "source": [
    "roll_days = ['location','today+0','today+1','today+2','today+3','today+4','today+5','today+6']\n",
    "location = [name]\n",
    "temperatures = list(lf['temp_max'][0:])\n",
    "string = location + temperatures\n",
    "print(f'New Row: {string}, with {len(string)-1}/7 days')\n",
    "new_forecast_row = pd.Series(string, index=roll_days, name=today)\n",
    "\n",
    "if today.strftime(\"%Y-%m-%d\") in temps.index:\n",
    "    print(f'File not saved. Date already exists in index.')\n",
    "else:\n",
    "    temps = temps.append(new_forecast_row)\n",
    "    file_name = '../data/temps_' + today.strftime(\"%Y-%m-%d\") + '.csv'\n",
    "    temps.to_csv(file_name) # backup file.\n",
    "    temps.to_csv('../data/temps.csv')\n",
    "    print('File Saved')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Manually save to file not used at this point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temps.to_csv(file_name) # backup file.\n",
    "# temps.to_csv('temps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.info()\n",
    "temps['location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_location()\n",
    "temps = temps[temps['location'] == 'Melbourne'].drop(['location'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Plotting Data\n",
    "- Load and plot weather forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn lineplot, takes care of most settings.\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data,title):\n",
    "    sns.set(rc={'figure.figsize':(12,5)})\n",
    "    ax = sns.lineplot(data=data.T,legend=None, dashes=False,) # transpose df and dashes beyond 6 cols thows errors.\n",
    "    ax.set_title(title, loc='center', fontsize=18)\n",
    "    return plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(temps,\"All Forecasts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows a pattern, but isn't clealy interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map(data,title):\n",
    "    fig, ax = plt.subplots(figsize = (10,10))\n",
    "    ax = sns.heatmap(data, annot=True, center=True, cmap = 'coolwarm',cbar_kws={'label': 'Degrees Celcius'})\n",
    "    ax.set_title(title, loc='center', fontsize=18)\n",
    "    ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=14, rotation=30)\n",
    "    ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=14, rotation=0)\n",
    "    ax.figure.axes[-1].yaxis.label.set_size(14)\n",
    "    ax.figure.axes[0].yaxis.label.set_size(14)\n",
    "    ax.figure.axes[0].xaxis.label.set_size(14)\n",
    "    return plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(temps,\"7 Day Forecasts From BOM (Decending to the left)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation: This chart should be read top to bottom, right to left.**       \n",
    "As the forecast date approaches (decending), the the colour change to the left reflects stregnthening and weaking of systems and the daily adjustment of forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Evaluate Forecast Accuracy\n",
    "Check forecast temperature for each day against the recorded temperature for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dates = temps.index # Keep non-datetime index list for charts. (avoid 00:00:00 ending)\n",
    "temps.index = pd.to_datetime(temps.index) # make index a datetime.\n",
    "\n",
    "def highlight_diags(data):\n",
    "    '''Highlight Forecast Lines'''\n",
    "    attr1 = 'background-color: lightgreen'\n",
    "    attr2 = 'background-color: salmon'\n",
    "    attr3 = 'background-color: lightblue'\n",
    "    \n",
    "    df_style = data.replace(data.values, '')\n",
    "    np.fill_diagonal(np.flipud(df_style), attr1)\n",
    "    np.fill_diagonal(np.flipud(df_style)[2:], attr2)\n",
    "    np.fill_diagonal(np.flipud(df_style)[4:], attr3)\n",
    "    return df_style\n",
    "\n",
    "temps.style.apply(highlight_diags, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date being forecast shifts down and to the left as the date approaches.   \n",
    "Note, the highlighting does not appear on GitHub. Please view file here. [Please view file here](https://github.com/bfgdigital/BOM_Weather/tree/main/assets/forecast_highlighting.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Acuracy Mechanism: Compare forecast to actual Temp.\n",
    "fac = pd.DataFrame()\n",
    "counter = list(range(len(temps)))\n",
    "columns = list(temps.columns)\n",
    "\n",
    "for i in counter:\n",
    "    # 7 day forecast inc today, so len can't exceed 7\n",
    "    if i < 7:\n",
    "        window = i \n",
    "        j = i\n",
    "    else: \n",
    "        window = 6\n",
    "        j = 6\n",
    "    \n",
    "    # Start date at most recent row\n",
    "    actual_date = temps.index[-1] # start with the last day\n",
    "    window_date = actual_date - pd.DateOffset(days=window) # Number of days in the past can't be more than those forecast\n",
    "    row_0 = temps.index[0] # We want to end when window date is equal to row_0.\n",
    "    \n",
    "    temps_list = [] # temporary holder of weeeks values.\n",
    "    while window_date >= row_0:\n",
    "        true_temp = int(temps.loc[actual_date][0]) # True temperature recorded on day\n",
    "        predicted_temp = int(temps.loc[window_date][window]) # data predicted on value of window\n",
    "        difference =  true_temp - predicted_temp\n",
    "        # loop \n",
    "        actual_date -= pd.DateOffset(days=1) # take off 1 day.\n",
    "        window_date -= pd.DateOffset(days=1) # take off 1 day.\n",
    "        # append\n",
    "        temps_list.append(difference)    \n",
    "    # Add list to df as series    \n",
    "    fac[columns[j]] = pd.Series(temps_list[::-1]) # Add list backwards.\n",
    "        \n",
    "fac.index = basic_dates\n",
    "fac, temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(fac,\"Forecast Variation (0 = 100% Accurate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation: This chart should be read top to bottom, right to left.**       \n",
    "Forecasts are generally accurate out to 3 days, with some error developing from 4 days on wards.  What is noteable is the error surrounding weather events. The largest amount of error occurs during the change in weather, as a front approaches for eg, while stable weather appears to be more easily predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4: Build Persistence Model\n",
    "- Build models for  Weather(t+i) = Weather(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistance Mechanism subtract each max temp from the one before.\n",
    "pmodel  = pd.Series([today - yesterday for today,yesterday in zip(temps['today+0'],temps['today+0'][1:])],index=temps.index[:len(temps.index)-1])\n",
    "pmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the persistance model we have is correct as each value in the list is the sum of the sequential temperature value subtracted. This gives us a baseline for how accurate \"Tomorrow's weather will be the same as today\" was for the days observed to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5: Compare the two models\n",
    "- Compare Persistance to the forecasts provided by the BOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence = pd.DataFrame()\n",
    "persistence['Persistence Accuracy'] = pmodel.values\n",
    "for i in range(1,7):\n",
    "    persistence[str(i)+' Day Forecast'] = pd.Series(fac['today+'+str(i)].values)\n",
    "persistence.index = basic_dates[:len(basic_dates)-1]\n",
    "persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(persistence,\"Persistence (far left) vs Forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the persistance model may be a good benchmark for forecasts greater than 4 days away.   \n",
    "To summarise, if you were to wager that the weather on a date 5 days from now, would be the closer to that of the day before rather than what the BOM has forecast, you would likely win.   \n",
    "\n",
    "This suggests the feasibility of using the persistence model as a weighted feature in forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 6: Can we use the Persistence model as a feature?\n",
    "This section wil attemtp to use historical data from the BOM with common forecasting models Facebook Prophet and Random Forest to see if combined with a Persisence model, we can forecast more accurately than the BOM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Forecast\n",
    "Using cleaned BOM data from EDA.   \n",
    "[Click here for EDA notebook locally](eda.ipynb#section_id1)   \n",
    "[Click here for EDA notebook GitHub](https://github.com/bfgdigital/BOM_Weather/blob/main/notebooks/eda.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('../data/weather.csv',infer_datetime_format=True,index_col=0)\n",
    "weather.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build forecast model\n",
    "Facebook Prophet is a popular and simple timeseries forecsting tool that is particularly effective with seasonal data.   \n",
    "[\"fbprophet\" documentation can be found here](https://facebook.github.io/prophet/docs/quick_start.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timeseries\n",
    "start_date = weather['max_temp_c'].index[0] # First data point\n",
    "end_date = weather['max_temp_c'].index[-1] # Last data point.\n",
    "print(f'Range begins {start_date} and ends {end_date}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet needs Date and values columns (ds and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(None)\n",
    "pdf['ds'] = weather.index # Create our date column\n",
    "pdf['y'] = weather['max_temp_c'].values\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations.\n",
    "- Data goes all the way back to 2013 recorded daily.   \n",
    "\n",
    "Because we have timeseries data we can resample and smooth the data using a Savgol filter to adjust for big temperature changes that occur suddenly that BOM forecasts appear to struggle with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf.index = pd.to_datetime(pdf['ds'])\n",
    "pdf = pdf.resample('6h').mean().bfill() # Resample dates to 6h intervals and back fill.\n",
    "pdf['ds'] = pdf.index\n",
    "print(pdf)\n",
    "plot_data(pdf['y'],\"Resampled To 6h Intervals\") # plot y\n",
    "pdf = pdf.reset_index(drop=True) # Perfer to have sequential index for smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoth Values\n",
    "- SavGol filter is excellent for smoothing a timeseries data.\n",
    "\n",
    "This generates smoother curves for the Prophet model to use for interpreting seasonality. Effectively softening outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "# Smooth with SavGol filter\n",
    "pdf_sg = pdf\n",
    "savgol = [savgol_filter(pdf_sg[i], 5, 3, mode='constant') for i in pdf_sg] # modes: 'mirror', 'constant', 'nearest', 'wrap' or 'interp'\n",
    "savgol = pd.DataFrame(savgol, columns=pd.to_datetime(pdf_sg.index), index=pdf_sg.columns)\n",
    "savgol = savgol.T # Needed a flip\n",
    "pdf['y'] = savgol['y']\n",
    "plot_data(pdf['y'],\"Smoothed Values\") # plot y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Facebook Prophet to forecast tomorrow's temperature\n",
    "Facebook Prophet has the ability to detect cycles which may help make more accurate forecasts   \n",
    "as more data is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet(weekly_seasonality=False)\n",
    "model.fit(pdf)\n",
    "future = model.make_future_dataframe(periods = 2) # forecast 2 days beyond available data.\n",
    "forecast = model.predict(future)\n",
    "figure = model.plot(forecast, xlabel = 'Date', ylabel = 'Temperature')\n",
    "print('\\n',f\"The forecast for tomorrow suggested by Facebook Prophet is: {float(forecast['yhat'][len(forecast)-1]):.2f}\",'\\n')\n",
    "prophet_forecast = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(2)  # show the dataframe.\n",
    "prophet_forecast.reset_index(drop=True,inplace=True)\n",
    "prophet_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet model appears to offer reasonable values.   \n",
    "Next to check the identified components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(forecast);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks promising, the Yearly trends look accurate the daily trend introduced by the Savgol filter looks to represent overnight temperature fluctuations of around 8¬∫ and the trend is based on the latest observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Max Temp with Random Forrest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = weather['max_temp_c']\n",
    "X = weather.drop(['max_temp_c'], axis=1)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=100, random_state=42)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch today's rainfall, and uv_index from our API forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign feature predictors**   \n",
    "BOM only supplies 2 days worth of UV predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_rf = 0 # assuming quality data\n",
    "q_maxt = 0 # assuming quality data\n",
    "q_mint = 0 # assuming quality data\n",
    "max_temps_2days = []\n",
    "min_temps_2days = []\n",
    "tomorrow_2days = []\n",
    "rain_2days = []\n",
    "uv_2days = []\n",
    "for i in range(1,3):\n",
    "    max_temps_2days.append(lf['temp_max'][i])\n",
    "    min_temps_2days.append(lf['temp_min'][i])\n",
    "    try:\n",
    "        rain_2days.append(float(lf['rain'][i]['amount']['max'])) # Using Max instead of Max-Min\n",
    "    except:\n",
    "        rain_2days.append(0) # Nan value when no rain.\n",
    "    uv_2days.append(lf['uv'][i]['max_index'])\n",
    "\n",
    "rf_features = pd.DataFrame([min_temps_2days, max_temps_2days, rain_2days, uv_2days],columns=['today+1','today+2'],index=['MinTemp','MaxTemp','Rain','UV'])\n",
    "rf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_forecast = []\n",
    "for i in rf_features:\n",
    "    [predicted_mt] = regr.predict([[rf_features.loc['Rain'][i], q_rf, rf_features.loc['MinTemp'][i], q_mint, q_maxt, rf_features.loc['UV'][i]]]) # sbracket both sides to remove from list.\n",
    "    score = regr.score(X, y) # R^2 (coefficient of determination) regression score function.\n",
    "    randomforest_forecast.append(predicted_mt)\n",
    "    print(f\"The temperature forecast by the BOM tomorrow is {rf_features.loc['MaxTemp'][i]} and by our model is {predicted_mt:.2f}, with {score:.2f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> This output also appears to return an acceptable output, however this model is still using future BOM foreast data for rain and uv, which technically means this model is somewhat cheating.   \n",
    "All the same it is still an interesting forecast.   \n",
    "    \n",
    "This model could be used with the persistence model of using today's recorded values for rain and uv features, however I will use the persistence model as part of the final model in the next step and don't want to over-weight yesterday's temperatures.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all the pieces together\n",
    "Build a new forecast and add it to existing forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bens_vs_bom = pd.read_csv('../data/ben_vs_bom.csv',infer_datetime_format=True,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomorrow = latest_forecast['data'][1]['date'][:10] # We want it as a string, not a datetime.\n",
    "dayafter = latest_forecast['data'][2]['date'][:10] # We want it as a string, not a datetime.\n",
    "\n",
    "if dayafter in bens_vs_bom.index:\n",
    "    print(f'Date is already in index, plese try later.')\n",
    "else:\n",
    "    # Day 1 Forecasts\n",
    "    persistence_forecast_1 = int(temps[::-1]['today+0'][0]) # Today's temp\n",
    "    prophet_forecast_1 = float(prophet_forecast['yhat'][0]) # Prophet temp\n",
    "    randomforest_forecast_1 = float(randomforest_forecast[0]) # Random Forest temp\n",
    "    bens_forecast_1 = (persistence_forecast_1 + prophet_forecast_1 + randomforest_forecast_1)/3 # Average of all three guesses.\n",
    "    BOM_forecast_1 = rf_features.loc['MaxTemp'][0] # BOM forecast\n",
    "    \n",
    "    # Day 1 Forecasts\n",
    "    persistence_forecast_2 = bens_forecast_1 # Yesterday's forecast temp\n",
    "    prophet_forecast_2 = float(prophet_forecast['yhat'][1]) # Prophet temp\n",
    "    randomforest_forecast_2 = float(randomforest_forecast[1]) # Random Forest temp\n",
    "    bens_forecast_2 = (persistence_forecast_2 + prophet_forecast_2 + randomforest_forecast_2)/3 # Average of all three guesses.\n",
    "    BOM_forecast_2 = rf_features.loc['MaxTemp'][1] # BOM forecast\n",
    "\n",
    "    forecasts_1 = [persistence_forecast_1, prophet_forecast_1, randomforest_forecast_1, bens_forecast_1, BOM_forecast_1]\n",
    "    forecasts_2 = [persistence_forecast_2, prophet_forecast_2, randomforest_forecast_2, bens_forecast_2, BOM_forecast_2]\n",
    "    \n",
    "    final_set = pd.DataFrame(None,columns=bens_vs_bom.columns)\n",
    "    final_set.loc[0] = pd.Series(forecasts_1, index=bens_vs_bom.columns)\n",
    "    final_set.loc[1] = pd.Series(forecasts_2, index=bens_vs_bom.columns)\n",
    "    final_set.index = [tomorrow,dayafter]\n",
    "    \n",
    "    if dayafter in bens_vs_bom.index:\n",
    "        print(f'File not saved. Date already exists in index, see you tomorrow.')\n",
    "    else:\n",
    "        bvb_filename = '../data/forecast_records/bvb_archive_' + todaystr + '.csv'\n",
    "        bens_vs_bom.to_csv(bvb_filename) # backup file before dropping last value.\n",
    "        bens_vs_bom.drop(bens_vs_bom.tail(1).index,inplace=True) # drop last row and update. (same as BOM model updates, dropping last value)\n",
    "        bens_vs_bom = bens_vs_bom.append(final_set)\n",
    "        bens_vs_bom.to_csv('../data/ben_vs_bom.csv') # backup file.\n",
    "        print('File Saved, Thanks for coming.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast is built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So to wrap up, what do our models forecast the weather will be tomorrow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bens_vs_bom.style.set_properties(**{'background-color': 'yellow'}, subset=['Bens Best Guess'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>The forecast is close, but get your weather forecast from the BOM.</strong> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The End."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
